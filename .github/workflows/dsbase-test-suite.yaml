################################################################################
# DataSHIELD GHA test suite - dsBase (curated refs matrix version)
# Now supports testing curated branches/tags from .github/dsbase-refs.txt
################################################################################
name: dsBase tests' suite

on:
  push:
  schedule:
    - cron: '0 0 * * 0'   # weekly
    # - cron: '0 1 * * *'   # nightly
  workflow_dispatch:

env:
  TARGET_REPOSITORY: datashield/dsBase
  PROJECT_NAME: dsBase

jobs:
  set-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.build.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4

      - name: Build matrix from LABEL=REF file (.github/dsbase-refs.txt)
        id: build
        run: |
          if [ ! -f .github/dsbase-refs.txt ]; then
            echo "ERROR: .github/dsbase-refs.txt not found."
            exit 1
          fi

          FILE=".github/dsbase-refs.txt"

          MATRIX_JSON=$(grep -v '^\s*#' "$FILE" | grep -v '^\s*$' | awk -F= '
            {
              label=$1
              ref=$2
              gsub(/^[ \t]+|[ \t]+$/, "", label)
              gsub(/^[ \t]+|[ \t]+$/, "", ref)
              printf "{\"label\":\"%s\",\"ref\":\"%s\"}\n", label, ref
            }
          ' | jq -s -c '.')

          echo "matrix=$MATRIX_JSON" >> $GITHUB_OUTPUT

  dsBase_test_suite:
    needs: set-matrix
    runs-on: ubuntu-latest
    timeout-minutes: 120
    permissions:
      contents: write

    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJson(needs.set-matrix.outputs.matrix) }}

    env:
      TEST_FILTER: '*'
      _r_check_system_clock_: 0
      REF_NAME: ${{ matrix.ref }}
      REF_LABEL: ${{ matrix.label }}
      WORKFLOW_ID: ${{ github.run_id }}-${{ github.run_attempt }}-${{ matrix.ref }}

    steps:
      - name: Checkout dsBase
        uses: actions/checkout@v4
        with:
          repository: ${{ env.TARGET_REPOSITORY }}
          token: ${{ github.token }}
          ref: ${{ matrix.ref }}
          fetch-depth: 0
          path: dsBase

      - name: Checkout dsTestsDashboard
        uses: actions/checkout@v4
        with:
          path: dsTestsDashboard

      - uses: r-lib/actions/setup-pandoc@v2

      - uses: r-lib/actions/setup-r@v2
        with:
          r-version: release
          use-public-rspm: true

      - uses: r-lib/actions/setup-r-dependencies@v2
        with:
          working-directory: dsBase
          dependencies: '"Imports"'
          needs: check
          cache-version: 1
          extra-packages: |
            cran::devtools
            cran::usethis

      - name: Devtools check
        run: |
          R -q -e "devtools::check(args = c('--no-tests','--no-examples'))"
        working-directory: dsBase
        continue-on-error: false

      - name: Run tests and generate coverage report
        working-directory: dsBase
        continue-on-error: false
        run: |
          Rscript -e '
            dir.create("logs");

            devtools::reload();

            # define output paths
            test_results_xml <- "logs/test_results.xml";
            coverage_csv <- "logs/coveragelist.csv";

            cat("=== Running testthat directly (debug mode) ===\n");
            cat("Working directory:", getwd(), "\n");
            cat("R version:", R.version.string, "\n");
            # check if the tests are in the right place
            cat("Tests found in:", list.files(path = "tests/testthat", full.names = TRUE), "\n");

            # run tests using testthat and save results to XML
            library(testthat);
            junit_rep <- testthat::JunitReporter$new(file = test_results_xml);
            progress_rep <- testthat::ProgressReporter$new(max_failures = 999999);
            multi_rep <- testthat::MultiReporter$new(reporters = list(progress_rep, junit_rep));
            testthat::test_dir("tests/testthat", filter = Sys.getenv("TEST_FILTER"), reporter = multi_rep, stop_on_failure = FALSE);

            # calculate coverage and write to CSV
            library(covr);
            coverage_result <- covr::package_coverage(type = c("none"));
            coverage_list <- covr::coverage_to_list(coverage_result);
            write.csv(coverage_list, coverage_csv, row.names = FALSE);
          '

      - name: Check for JUnit errors
        run: |
          issue_count=$(sed 's/failures="0" errors="0"//' test_results.xml | grep -c errors= || true)
          echo "Number of testsuites with issues: $issue_count"
          sed 's/failures="0" errors="0"//' test_results.xml | grep errors= > issues.log || true
          cat issues.log || true
          exit $issue_count
        working-directory: dsBase/logs

      - name: Write versions to file
        run: |
          echo "ref:${{ env.REF_NAME }}" > ${{ env.WORKFLOW_ID }}.txt
          echo "ref_label:${{ env.REF_LABEL }}" >> ${{ env.WORKFLOW_ID }}.txt
          echo "os:$(lsb_release -ds)" >> ${{ env.WORKFLOW_ID }}.txt
          echo "R:$(R --version | head -n1)" >> ${{ env.WORKFLOW_ID }}.txt
          Rscript --vanilla -e 'sessionInfo()' >> session_info_${{ env.WORKFLOW_ID }}.txt
        working-directory: dsBase/logs

      - name: Upload logs artefact
        uses: actions/upload-artifact@v4
        with:
          name: logs-ref_${{ matrix.ref }}-label_${{ matrix.label }}
          path: dsBase/logs
          if-no-files-found: error

      - name: Dump environment (on failure)
        if: failure()
        run: |
          echo -e "\n#############################"
          echo -e "ls /: ######################"
          ls -al .
          echo -e "\n#############################"
          echo -e "lscpu: ######################"
          lscpu
          echo -e "\n#############################"
          echo -e "memory: #####################"
          free -m
          echo -e "\n#############################"
          echo -e "env: ########################"
          env
          echo -e "\n#############################"
          echo -e "R sessionInfo(): ############"
          R -e 'sessionInfo()'
          sudo apt install tree -y
          tree .

  publish-results:
    name: Publish aggregated results
    needs: dsBase_test_suite
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout dsTestsDashboard
        uses: actions/checkout@v4
        with:
          path: dsTestsDashboard
          fetch-depth: 0

      - name: Download all artefacts
        uses: actions/download-artifact@v4
        with:
          path: artefacts

      - name: Merge artefacts into dashboard structure
        run: |
          set -e
          cd dsTestsDashboard

          echo "Artefacts downloaded:"
          ls -R ../artefacts || true

          for dir in ../artefacts/logs-*; do
            if [ -d "$dir" ]; then
              BASENAME=$(basename "$dir")

              # extract ref (between logs-ref_ and -label_)
              REF="${BASENAME#logs-ref_}"
              REF="${REF%%-label_*}"

              # extract label (after -label_)
              LABEL="${BASENAME#*-label_}"

              echo "Processing:"
              echo "  ref:   $REF"
              echo "  label: $LABEL"

              WORKFLOW_ID="${{ github.run_id }}-${{ github.run_attempt }}-${REF}"
              TARGET_DIR="logs/${{ env.PROJECT_NAME }}/${LABEL}/${WORKFLOW_ID}/"
              mkdir -p "$TARGET_DIR"
              cp -rv "$dir"/* "$TARGET_DIR" || true
            fi
          done
        env:
          PROJECT_NAME: ${{ env.PROJECT_NAME }}

      - name: Commit and push once
        run: |
          cd dsTestsDashboard

          git config user.email "github-actions[bot]@users.noreply.github.com"
          git config user.name "github-actions[bot]"

          # rebase instead of pull to avoid merge commits
          git pull --rebase origin main || true

          git add .

          if git diff --cached --quiet; then
            echo "No changes to commit"
            exit 0
          fi

          git commit -m "Aggregated dsBase results @ ${{ github.run_id }}-${{ github.run_attempt }}"
          git push origin main
