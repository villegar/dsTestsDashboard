################################################################################
# DataSHIELD GHA test suite - dsBaseClient
# Matrix-driven from curated refs file (.github/dsbaseclient-refs.txt)
################################################################################
name: dsBaseClient tests' suite

on:
  push:
  schedule:
    - cron: '0 0 * * 6'   # weekly
    # - cron: '0 1 * * *'   # nightly
  workflow_dispatch:

env:
  TARGET_REPOSITORY: datashield/dsBaseClient
  PROJECT_NAME: dsBaseClient

jobs:
  set-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.build.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4

      - name: Build matrix from file (.github/dsbaseclient-refs.txt)
        id: build
        run: |
          if [ ! -f .github/dsbaseclient-refs.txt ]; then
            echo "ERROR: .github/dsbaseclient-refs.txt not found."
            exit 1
          fi

          FILE=".github/dsbaseclient-refs.txt"

          MATRIX_JSON=$(grep -v '^\s*#' "$FILE" | grep -v '^\s*$' | awk -F= '
            {
              label=$1
              ref=$2
              dsdangerclient=$3
              gsub(/^[ \t]+|[ \t]+$/, "", label)
              gsub(/^[ \t]+|[ \t]+$/, "", ref)
              gsub(/^[ \t]+|[ \t]+$/, "", dsdangerclient)
              printf "{\"label\":\"%s\",\"ref\":\"%s\",\"dsdangerclient\":\"%s\"}\n", label, ref, dsdangerclient
            }
          ' | jq -s -c '.')

          echo "matrix=$MATRIX_JSON" >> $GITHUB_OUTPUT

  dsBaseClient_test_suite:
    needs: set-matrix
    runs-on: ubuntu-latest
    timeout-minutes: 180
    permissions:
      contents: write

    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJson(needs.set-matrix.outputs.matrix) }}

    env:
      TEST_FILTER: '_-|datachk-|smk-|arg-|disc-|smk_expt-|expt-|math-'
      REF_NAME: ${{ matrix.ref }}
      REF_LABEL: ${{ matrix.label }}
      REF_DSDANGERCLIENT: ${{ matrix.dsdangerclient }}
      WORKFLOW_ID: ${{ github.run_id }}-${{ github.run_attempt }}-${{ matrix.ref }}

    steps:
      - name: Checkout dsTestsDashboard
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Checkout dsBaseClient
        uses: actions/checkout@v4
        with:
          repository: ${{ env.TARGET_REPOSITORY }}
          token: ${{ github.token }}
          ref: ${{ matrix.ref }}
          fetch-depth: 0
          path: dsBaseClient

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libxml2-dev \
            libcurl4-openssl-dev \
            libssl-dev \
            libgsl-dev \
            libgit2-dev \
            libharfbuzz-dev \
            libfribidi-dev \
            libmagick++-dev \
            xml-twig-tools

      - uses: r-lib/actions/setup-pandoc@v2

      - uses: r-lib/actions/setup-r@v2
        with:
          r-version: release
          http-user-agent: release
          use-public-rspm: true

      - uses: r-lib/actions/setup-r-dependencies@v2
        with:
          working-directory: dsBaseClient
          dependencies: 'c("Imports", "Suggests")'
          cache-version: 1
          needs: check
          extra-packages: |
            cran::MolgenisArmadillo

      - name: Install dsDangerClient and dependencies
        run: |
          echo "Installing dsDangerClient/$REF_DSDANGERCLIENT and dependencies"
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev  # Required system dependencies for R packages
          R -e "install.packages('devtools')"  # Install devtools if it's not already installed
          R -e "devtools::install_github('datashield/dsDangerClient', ref = '${{ matrix.dsdangerclient }}')"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Devtools checks
        run: |
          R -q -e "devtools::check(args = c('--no-examples', '--no-tests'))"
        working-directory: dsBaseClient
        continue-on-error: true

      - name: Install dsBaseClient explicitly
        run: |
          echo "Installing dsBaseClient after check"
          R -e "devtools::install('.')"
        working-directory: dsBaseClient

      - name: Start Armadillo
        run: docker compose -f docker-compose_armadillo.yml up -d
        working-directory: dsBaseClient

      - name: Wait for Armadillo API
        run: |
          echo "Waiting for Armadillo..."
          until curl -s http://localhost:8080/packages > /dev/null; do
            sleep 5
          done
          echo "Armadillo ready."

      - name: Install test datasets
        run: |
          R -q -f "molgenis_armadillo-upload_testing_datasets.R"
        working-directory: dsBaseClient/tests/testthat/data_files

      - name: Install latest dsBase to Armadillo
        run: |
          set -e

          echo "Looking for dsBase_* -permissive tarballs..."
          ls -1 dsBase_*-permissive.tar.gz || true

          # find latest version using version sort (-V handles X.Y.Z correctly)
          LATEST_TARBALL=$(ls -1 dsBase_*-permissive.tar.gz 2>/dev/null | sort -V | tail -n 1)

          if [ -z "$LATEST_TARBALL" ]; then
            echo "❌ No dsBase_* -permissive.tar.gz file found in repo"
            exit 1
          fi

          echo "✅ Latest dsBase package detected: $LATEST_TARBALL"

          # extract version for logging
          VERSION=$(echo "$LATEST_TARBALL" | sed -E 's/^dsBase_([0-9.]+)-permissive\.tar\.gz$/\1/')
          echo "Installing dsBase version: $VERSION"

          # check Armadillo API is reachable
          curl -u admin:admin -X GET http://localhost:8080/packages

          # install the latest tarball
          curl -u admin:admin \
            -H 'Content-Type: multipart/form-data' \
            -F "file=@${LATEST_TARBALL}" \
            -X POST http://localhost:8080/install-package

          docker restart dsbaseclient-armadillo-1

          until curl -s http://localhost:8080/packages > /dev/null; do
            sleep 5
          done

          # whitelist dsBase (package name stays constant)
          curl -u admin:admin -X POST http://localhost:8080/whitelist/dsBase

          # install dsBase locally too
          Rscript -e 'install.packages(c("RANN", "reshape2", "polycor", "gamlss", "gamlss.dist", "mice", "childsds"), dependencies = TRUE)'
          R CMD INSTALL $LATEST_TARBALL
        working-directory: dsBaseClient

      - name: Run tests and generate coverage report
        working-directory: dsBaseClient
        continue-on-error: false
        run: |
          Rscript -e '
            out_dir <- file.path(getwd(), "logs");
            dir.create(out_dir, recursive = TRUE, showWarnings = FALSE);

            devtools::reload();
            library(dsBase);
            library(dsBaseClient);

            # define output paths
            test_results_xml <- file.path(out_dir, "test_results.xml");
            coverage_csv <- file.path(out_dir, "coveragelist.csv");
            coverage_xml <- file.path(out_dir, "coverage.xml");

            cat("=== Running testthat directly (debug mode) ===\n");
            cat("Working directory:", getwd(), "\n");
            cat("R version:", R.version.string, "\n");
            cat("Writing outputs to: ", out_dir, "\n");

            # run tests using testthat and save results to XML
            tryCatch({
              # attempt to delete very slow test
              slow_test_path <- file.path(getwd(), "tests/testthat/test-smk-ds.glm-poisson.R")
              if (file.exists(slow_test_path)) {
                unlink(slow_test_path, force = TRUE)
              }
              library(testthat);
              junit_rep <- testthat::JunitReporter$new(file = test_results_xml);
              progress_rep <- testthat::ProgressReporter$new(max_failures = 999999);
              multi_rep <- testthat::MultiReporter$new(reporters = list(progress_rep, junit_rep));
              testthat::test_dir("tests/testthat", filter = Sys.getenv("TEST_FILTER"), reporter = multi_rep, stop_on_failure = FALSE);
            }, error = function(e) {
              message("[ERROR] Testing: ", e);
            });

            # calculate coverage and write to CSV
            tryCatch({
              library(covr);
              coverage_result <- covr::package_coverage(type = c("tests"));
              coverage_list <- covr::coverage_to_list(coverage_result);
              write.csv(coverage_list, coverage_csv, row.names = FALSE);

              # generate coverage xml to be push to Codecov
              covr::to_cobertura(coverage_result, coverage_xml)
            }, error = function(e) {
              message("[ERROR] Code coverage: ", e);
            });
          '

      - name: Write versions to file
        run: |
          echo "ref:${{ env.REF_NAME }}" > ${{ env.WORKFLOW_ID }}.txt
          echo "ref_label:${{ env.REF_LABEL }}" >> ${{ env.WORKFLOW_ID }}.txt
          echo "os:$(lsb_release -ds)" >> ${{ env.WORKFLOW_ID }}.txt
          echo "R:$(R --version | head -n1)" >> ${{ env.WORKFLOW_ID }}.txt
          Rscript --vanilla -e 'sessionInfo()' >> session_info_${{ env.WORKFLOW_ID }}.txt
        working-directory: dsBaseClient/logs

      - name: Upload logs artefact
        uses: actions/upload-artifact@v4
        with:
          name: logs-ref_${{ matrix.ref }}-label_${{ matrix.label }}
          path: dsBaseClient/logs
          if-no-files-found: error

      - name: Dump environment (on failure)
        if: failure()
        run: |
          echo -e "\n#############################"
          echo -e "ls /: ######################"
          ls -al .
          echo -e "\n#############################"
          echo -e "lscpu: ######################"
          lscpu
          echo -e "\n#############################"
          echo -e "memory: #####################"
          free -m
          echo -e "\n#############################"
          echo -e "env: ########################"
          env
          echo -e "\n#############################"
          echo -e "R sessionInfo(): ############"
          R -e 'sessionInfo()'
          sudo apt install tree -y
          tree .

  publish-results:
    name: Publish aggregated results
    needs: dsBaseClient_test_suite
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout dsTestsDashboard
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download all artefacts
        uses: actions/download-artifact@v4
        with:
          path: artefacts

      - name: Merge artefacts into dashboard structure
        run: |
          set -e

          echo "Artefacts downloaded:"
          ls -R artefacts || true

          for dir in artefacts/logs-*; do
            if [ -d "$dir" ]; then
              BASENAME=$(basename "$dir")

              # extract ref (between logs-ref_ and -label_)
              REF="${BASENAME#logs-ref_}"
              REF="${REF%%-label_*}"

              # extract label (after -label_)
              LABEL="${BASENAME#*-label_}"

              echo "Processing:"
              echo "  ref:   $REF"
              echo "  label: $LABEL"

              WORKFLOW_ID="${{ github.run_id }}-${{ github.run_attempt }}-${REF}"
              TARGET_DIR="logs/${{ env.PROJECT_NAME }}/${LABEL}/${WORKFLOW_ID}/"
              mkdir -p "$TARGET_DIR"
              cp -rv "$dir"/* "$TARGET_DIR" || true
            fi
          done
        env:
          PROJECT_NAME: ${{ env.PROJECT_NAME }}

      - name: Commit and push once
        run: |
          rm -rf artefacts

          git config user.email "github-actions[bot]@users.noreply.github.com"
          git config user.name "github-actions[bot]"

          # rebase instead of pull to avoid merge commits
          git pull --rebase origin main || true

          git add .

          if git diff --cached --quiet; then
            echo "No changes to commit"
            exit 0
          fi

          git commit -m "Aggregated dsBaseClient results @ ${{ github.run_id }}-${{ github.run_attempt }}"
          git push origin main
