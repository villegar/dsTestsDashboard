################################################################################
# DataSHIELD GHA test suite - dsBaseClient
# Matrix-driven from curated refs file (.github/dsbaseclient-refs.txt)
################################################################################
name: dsBaseClient tests' suite

on:
  push:
  schedule:
    - cron: '0 0 * * 6'   # weekly
    # - cron: '0 1 * * *'   # nightly
  workflow_dispatch:

env:
  TARGET_REPOSITORY: datashield/dsBaseClient
  PROJECT_NAME: dsBaseClient

jobs:
  set-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.build.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4

      - name: Build matrix from file (.github/dsbaseclient-refs.txt)
        id: build
        run: |
          if [ ! -f .github/dsbaseclient-refs.txt ]; then
            echo "ERROR: .github/dsbaseclient-refs.txt not found."
            exit 1
          fi

          FILE=".github/dsbaseclient-refs.txt"

          MATRIX_JSON=$(grep -v '^\s*#' "$FILE" | grep -v '^\s*$' | awk -F= '
            {
              label=$1
              ref=$2
              dsdangerclient=$3
              docker_image=$4
              gsub(/^[ \t]+|[ \t]+$/, "", label)
              gsub(/^[ \t]+|[ \t]+$/, "", ref)
              gsub(/^[ \t]+|[ \t]+$/, "", dsdangerclient)
              gsub(/^[ \t]+|[ \t]+$/, "", docker_image)
              printf "{\"label\":\"%s\",\"ref\":\"%s\",\"dsdangerclient\":\"%s\",\"docker_image\":\"%s\"}\n", label, ref, dsdangerclient, docker_image
            }
          ' | jq -s -c '.')

          echo "matrix=$MATRIX_JSON" >> $GITHUB_OUTPUT

  dsBaseClient_test_suite:
    needs: set-matrix
    runs-on: ubuntu-latest
    timeout-minutes: 240
    permissions:
      contents: write

    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJson(needs.set-matrix.outputs.matrix) }}
        coverage_shard:
          - "_-"
          - "arg-"
          - "datachk-"
          - "math-"
          - "disc-"
          - "smk-"
          - "expt-"

    env:
      TEST_FILTER: ${{ matrix.coverage_shard }}
      COVERAGE_SHARD: ${{ matrix.coverage_shard }}
      REF_NAME: ${{ matrix.ref }}
      REF_LABEL: ${{ matrix.label }}
      REF_DSDANGERCLIENT: ${{ matrix.dsdangerclient }}
      DOCKER_IMAGE: ${{ matrix.docker_image }}
      WORKFLOW_ID: ${{ github.run_id }}-${{ github.run_attempt }}-${{ matrix.ref }}
      R_COVR_FIX_PARALLEL: false
      TESTTHAT_CPUS: 1
      R_MAX_VSIZE: 4Gb

    steps:
      - name: Checkout dsTestsDashboard
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Checkout dsBaseClient
        uses: actions/checkout@v4
        with:
          repository: ${{ env.TARGET_REPOSITORY }}
          token: ${{ github.token }}
          ref: ${{ matrix.ref }}
          fetch-depth: 0
          path: dsBaseClient

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libxml2-dev \
            libcurl4-openssl-dev \
            libssl-dev \
            libgsl-dev \
            libgit2-dev \
            libharfbuzz-dev \
            libfribidi-dev \
            libmagick++-dev \
            xml-twig-tools

      - uses: r-lib/actions/setup-pandoc@v2

      - uses: r-lib/actions/setup-r@v2
        with:
          r-version: release
          http-user-agent: release
          use-public-rspm: true

      - uses: r-lib/actions/setup-r-dependencies@v2
        with:
          working-directory: dsBaseClient
          dependencies: 'c("Imports", "Suggests")'
          cache-version: 1
          needs: check
          extra-packages: |
            cran::MolgenisArmadillo
            cran::MolgenisAuth

      - name: Install dsDangerClient and dependencies
        run: |
          echo "Installing dsDangerClient/$REF_DSDANGERCLIENT and dependencies"
          R -e "install.packages('devtools')"  # Install devtools if it's not already installed
          R -e "devtools::install_github('datashield/dsDangerClient', ref = '${{ matrix.dsdangerclient }}')"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Install dsBaseClient explicitly
        run: |
          echo "Installing dsBaseClient after check"
          R --vanilla -e "devtools::install('.')"
        working-directory: dsBaseClient

      - name: Cleanup stale Docker containers and ports (CRITICAL)
        run: |
          echo "Cleaning old containers..."
          docker ps -a || true

          # Stop any containers using 8080/8443
          docker ps -q --filter "publish=8080" | xargs -r docker stop || true
          docker ps -q --filter "publish=8443" | xargs -r docker stop || true

          # Remove dangling containers & networks from previous runs
          docker container prune -f || true
          docker network prune -f || true

          # Kill any process binding 8080 just in case
          sudo lsof -i :8080 || true
          sudo fuser -k 8080/tcp || true

      - name: Generate dynamic docker-compose override to expose 8443
        run: |
          SERVICE=$(docker compose -f docker-compose_armadillo.yml config --services | head -n 1)
          echo "Detected service: $SERVICE"

          cat > docker-compose.override.yml <<EOF
          services:
            $SERVICE:
              ports:
                - "8080:8080"
                - "8443:8443"
              image: $DOCKER_IMAGE
          EOF
        working-directory: dsBaseClient

      - name: Start Armadillo
        run: docker compose -f docker-compose_armadillo.yml -f docker-compose.override.yml up -d
        working-directory: dsBaseClient

      - name: Wait for Armadillo (HTTPS + API)
        run: |
          set -e

          echo "Phase 1: Waiting for API (8080)..."
          for i in {1..60}; do
            if curl -s http://localhost:8080/packages > /dev/null; then
              echo "API ready"
              break
            fi
            sleep 5
          done

          echo "Phase 2: Waiting for HTTPS (8443 handshake)..."
          for i in {1..60}; do
            # Only test TLS handshake, not full response
            if timeout 3 bash -c "</dev/tcp/127.0.0.1/8443" 2>/dev/null; then
              echo "8443 socket accepting connections"
              exit 0
            fi
            sleep 5
          done

          echo "ERROR: Armadillo never became ready"
          docker compose -f docker-compose_armadillo.yml logs --tail=200
          exit 1

      - name: Install test datasets
        run: |
          R --vanilla -q -f "molgenis_armadillo-upload_testing_datasets.R"
        working-directory: dsBaseClient/tests/testthat/data_files

      - name: Install latest dsBase to Armadillo
        run: |
          set -e

          echo "Looking for dsBase_* -permissive tarballs..."
          ls -1 dsBase_*-permissive.tar.gz || true

          # find latest version using version sort (-V handles X.Y.Z correctly)
          LATEST_TARBALL=$(ls -1 dsBase_*-permissive.tar.gz 2>/dev/null | sort -V | tail -n 1)

          if [ -z "$LATEST_TARBALL" ]; then
            echo "❌ No dsBase_* -permissive.tar.gz file found in repo"
            exit 1
          fi

          echo "✅ Latest dsBase package detected: $LATEST_TARBALL"

          # extract version for logging
          VERSION=$(echo "$LATEST_TARBALL" | sed -E 's/^dsBase_([0-9.]+)-permissive\.tar\.gz$/\1/')
          echo "Installing dsBase version: $VERSION"

          # check Armadillo API is reachable
          curl -u admin:admin -X GET http://localhost:8080/packages

          # install the latest tarball
          curl -u admin:admin \
            -H 'Content-Type: multipart/form-data' \
            -F "file=@${LATEST_TARBALL}" \
            -X POST http://localhost:8080/install-package

          echo "Waiting for package registry refresh (no restart)..."
          sleep 10

          # just verify API still responds
          curl -u admin:admin -X GET http://localhost:8080/packages

          # whitelist dsBase (package name stays constant)
          curl -u admin:admin -X POST http://localhost:8080/whitelist/dsBase

          # install dsBase locally too
          Rscript --vanilla -e 'options(repos = c(CRAN = "https://cran.rstudio.com")); install.packages(c("RANN", "reshape2", "polycor", "gamlss", "gamlss.dist", "mice", "childsds"), dependencies = TRUE)'
          R CMD INSTALL $LATEST_TARBALL
        working-directory: dsBaseClient

      - name: Run tests and store in XML file
        working-directory: dsBaseClient
        continue-on-error: true
        run: |
          Rscript --vanilla -e '
            out_dir <- file.path(getwd(), "logs");
            dir.create(out_dir, recursive = TRUE, showWarnings = FALSE);

            # devtools::reload();
            library(dsBase);
            library(dsBaseClient);

            # define output paths
            # test_results_xml <- file.path(out_dir, "test_results.xml");
            test_results_xml <- file.path(out_dir, paste0("test_results_", Sys.getenv("COVERAGE_SHARD"), ".xml"));

            cat("=== Running testthat directly (debug mode) ===\n");
            cat("Working directory:", getwd(), "\n");
            cat("R version:", R.version.string, "\n");
            cat("Writing outputs to: ", out_dir, "\n");

            # run tests using testthat and save results to XML
            tryCatch({
              library(testthat);
              junit_rep <- testthat::JunitReporter$new(file = test_results_xml);
              progress_rep <- testthat::ProgressReporter$new(max_failures = 999999);
              multi_rep <- testthat::MultiReporter$new(reporters = list(progress_rep, junit_rep));
              # to fix issue with missing default_driver for Armadillo
              Sys.setenv(R_DEFAULT_DRIVER = "ArmadilloDriver");
              options(default_driver = "ArmadilloDriver");
              # to fix issue with mismatch in single quotes
              options(encoding = "UTF-8")
              Sys.setlocale("LC_CTYPE", "C")
              testthat::test_package(Sys.getenv("PROJECT_NAME"), filter = Sys.getenv("TEST_FILTER"), reporter = multi_rep, stop_on_failure = FALSE);
            }, error = function(e) {
              warning(e);
            });
          '

      - name: Run code coverage (sharded, memory-safe)
        working-directory: dsBaseClient
        continue-on-error: true
        run: |
          Rscript --vanilla -e '
            out_dir <- file.path(getwd(), "logs");
            dir.create(out_dir, recursive = TRUE, showWarnings = FALSE);

            cat("=== SHARDED COVR RUN ===\n");
            cat("Shard filter:", Sys.getenv("COVERAGE_SHARD"), "\n");

            # hard memory + parallel protection
            Sys.setenv(TESTTHAT_CPUS = 1);
            Sys.setenv(R_COVR = "true");
            options(mc.cores = 1);

            # load libraries
            # devtools::reload();
            library(dsBase);
            library(dsBaseClient);
            library(covr);
            library(testthat);

            # to fix issue with missing default_driver for Armadillo
            Sys.setenv(R_DEFAULT_DRIVER = "ArmadilloDriver");
            options(default_driver = "ArmadilloDriver");
            # to fix issue with mismatch in single quotes
            options(encoding = "UTF-8")
            Sys.setlocale("LC_CTYPE", "C")

            # define output paths
            coverage_csv <- file.path(out_dir, paste0("coveragelist_", Sys.getenv("COVERAGE_SHARD"), ".csv"));
            coverage_xml <- file.path(out_dir, paste0("coverage_", Sys.getenv("COVERAGE_SHARD"), ".xml"));

            cat("=== Running testthat directly (debug mode) ===\n");
            cat("Working directory:", getwd(), "\n");
            cat("R version:", R.version.string, "\n");
            cat("Writing outputs to: ", out_dir, "\n");

            # calculate coverage and store results
            tryCatch({
              # explicitly enumerate ONLY shard test files (critical for memory)
              shard_tests <- testthat::find_test_scripts(
                  path = "tests/testthat",
                  filter = Sys.getenv("COVERAGE_SHARD")
                );

              cat("Shard tests:", length(shard_tests), "\n");

              if (length(shard_tests) == 0) {
                stop("No tests matched shard filter: ", Sys.getenv("COVERAGE_SHARD"));
              }

              # TRUE sharded coverage: only these test files drive instrumentation
              coverage_result <- covr::package_coverage(
                type = "none",
                quiet = FALSE,
                clean = TRUE,
                code = {
                  sapply(shard_tests, testthat::test_file)
                  # testthat::test_package(Sys.getenv("PROJECT_NAME"), filter = Sys.getenv("TEST_FILTER"), reporter = multi_rep, stop_on_failure = FALSE)
                }
              );

              coverage_list <- covr::coverage_to_list(coverage_result);
              write.csv(coverage_list, coverage_csv, row.names = FALSE);

              # generate coverage xml to be push to Codecov
              covr::to_cobertura(coverage_result, coverage_xml)
            }, error = function(e) {
              cat("Coverage shard failed:", conditionMessage(e), "\n")
              warning(e);
            });
          '

      - name: Write versions to file
        run: |
          echo "ref:${{ env.REF_NAME }}" > ${{ env.WORKFLOW_ID }}.txt
          echo "ref_label:${{ env.REF_LABEL }}" >> ${{ env.WORKFLOW_ID }}.txt
          echo "os:$(lsb_release -ds)" >> ${{ env.WORKFLOW_ID }}.txt
          echo "R:$(R --version | head -n1)" >> ${{ env.WORKFLOW_ID }}.txt
          Rscript --vanilla -e 'sessionInfo()' >> session_info_${{ env.WORKFLOW_ID }}.txt
        working-directory: dsBaseClient/logs

      - name: Upload logs artefact
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: logs-ref_${{ matrix.ref }}-label_${{ matrix.label }}-shard_${{ matrix.coverage_shard }}
          path: dsBaseClient/logs
          if-no-files-found: error

      - name: Dump environment (on failure)
        if: failure()
        run: |
          echo -e "\n#############################"
          echo -e "ls /: ######################"
          ls -al .
          echo -e "\n#############################"
          echo -e "lscpu: ######################"
          lscpu
          echo -e "\n#############################"
          echo -e "memory: #####################"
          free -m
          echo -e "\n#############################"
          echo -e "env: ########################"
          env
          echo -e "\n#############################"
          echo -e "R sessionInfo(): ############"
          R -e 'sessionInfo()'
          sudo apt install tree -y
          tree .

  merge-coverage-tests:
    name: Merge coverage & test shards
    needs: dsBaseClient_test_suite
    runs-on: ubuntu-latest

    steps:
      - name: Checkout dsTestsDashboard
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download all artefacts
        uses: actions/download-artifact@v4
        with:
          path: artefacts

      - uses: r-lib/actions/setup-r@v2
        with:
          r-version: release

      - name: Merge coverage CSV and XML
        run: |
          Rscript --vanilla -e '
            library(covr)
            library(dplyr)

            artefact_dirs <- list.dirs("artefacts", recursive = TRUE, full.names = TRUE)

            csv_files <- list.files(
              artefact_dirs,
              pattern = "^coveragelist_.*\\.csv$",
              full.names = TRUE
            )

            xml_files <- list.files(
              artefact_dirs,
              pattern = "^coverage_.*\\.xml$",
              full.names = TRUE
            )

            cat("Found CSV shards:", length(csv_files), "\n")
            cat("Found XML shards:", length(xml_files), "\n")

            if (length(csv_files) == 0) {
              stop("No coverage CSV shards found")
            }

            # ---- Merge CSV (line-level union with max hit count) ----
            cov_list <- lapply(csv_files, read.csv, stringsAsFactors = FALSE)

            merged_cov <- bind_rows(cov_list) |>
              group_by(filename, functions, line) |>
              summarise(
                value = max(value, na.rm = TRUE),
                .groups = "drop"
              )

            dir.create("merged_coverage", showWarnings = FALSE)

            merged_csv <- "merged_coverage/coveragelist_merged.csv"
            write.csv(merged_cov, merged_csv, row.names = FALSE)

            cat("Merged CSV written to:", merged_csv, "\n")

            # ---- Reconstruct a covr object and export single XML ----
            # covr can rebuild coverage from list format
            cov_obj <- covr::as_coverage(merged_cov)

            merged_xml <- "merged_coverage/coverage_merged.xml"
            covr::to_cobertura(cov_obj, merged_xml)

            cat("Merged XML written to:", merged_xml, "\n")
          '

      - name: Merge tests XML
        run: |
          Rscript --vanilla -e '
            library(covr)
            library(dplyr)

            artefact_dirs <- list.dirs("artefacts", recursive = TRUE, full.names = TRUE)

            xml_files <- list.files(
              artefact_dirs,
              pattern = "^test_results_.*\\.xml$",
              full.names = TRUE
            )

            cat("Found XML shards:", length(xml_files), "\n")

            dir.create("merged_coverage", showWarnings = FALSE)

            file.rename(xml_files, file.path("merged_coverage", xml_files))

            # # ---- Reconstruct a covr object and export single XML ----
            # # covr can rebuild coverage from list format
            # cov_obj <- covr::as_coverage(merged_cov)
            #
            # merged_xml <- "merged_coverage/coverage_merged.xml"
            # covr::to_cobertura(cov_obj, merged_xml)
            #
            # cat("Merged XML written to:", merged_xml, "\n")
          '

      - name: Upload merged coverage artefact
        uses: actions/upload-artifact@v4
        with:
          name: merged-coverage
          path: merged_coverage

  publish-results:
    name: Publish aggregated results
    needs: merge-coverage-tests
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout dsTestsDashboard
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download all artefacts
        uses: actions/download-artifact@v4
        with:
          path: artefacts

      - name: Merge artefacts into dashboard structure
        run: |
          set -e

          echo "Artefacts downloaded:"
          ls -R artefacts || true

          for dir in artefacts/logs-*; do
            if [ -d "$dir" ]; then
              BASENAME=$(basename "$dir")

              # extract ref (between logs-ref_ and -label_)
              REF="${BASENAME#logs-ref_}"
              REF="${REF%%-label_*}"

              # extract label (after -label_)
              LABEL="${BASENAME#*-label_}"

              echo "Processing:"
              echo "  ref:   $REF"
              echo "  label: $LABEL"

              WORKFLOW_ID="${{ github.run_id }}-${{ github.run_attempt }}-${REF}"
              TARGET_DIR="logs/${{ env.PROJECT_NAME }}/${LABEL}/${WORKFLOW_ID}/"
              mkdir -p "$TARGET_DIR"
              cp -rv "$dir"/* "$TARGET_DIR" || true
            fi
          done

          for dir in artefacts/merged_coverage/*; do
            if [ -d "$dir" ]; then
              echo "$dir"
              # BASENAME=$(basename "$dir")
              #
              # # extract ref (between logs-ref_ and -label_)
              # REF="${BASENAME#logs-ref_}"
              # REF="${REF%%-label_*}"
              #
              # # extract label (after -label_)
              # LABEL="${BASENAME#*-label_}"
              #
              # echo "Processing:"
              # echo "  ref:   $REF"
              # echo "  label: $LABEL"
              #
              # WORKFLOW_ID="${{ github.run_id }}-${{ github.run_attempt }}-${REF}"
              # TARGET_DIR="logs/${{ env.PROJECT_NAME }}/${LABEL}/${WORKFLOW_ID}/"
              # mkdir -p "$TARGET_DIR"
              # cp -rv "$dir"/* "$TARGET_DIR" || true
            fi
          done
        env:
          PROJECT_NAME: ${{ env.PROJECT_NAME }}

      - name: Commit and push once
        run: |
          rm -rf artefacts

          git config user.email "github-actions[bot]@users.noreply.github.com"
          git config user.name "github-actions[bot]"

          # rebase instead of pull to avoid merge commits
          git pull --rebase origin main || true

          git add .

          if git diff --cached --quiet; then
            echo "No changes to commit"
            exit 0
          fi

          git commit -m "Aggregated dsBaseClient results @ ${{ github.run_id }}-${{ github.run_attempt }}"
          git push origin main
