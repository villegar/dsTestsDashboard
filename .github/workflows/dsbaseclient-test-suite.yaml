################################################################################
# DataSHIELD GHA test suite - dsBaseClient
# Matrix-driven from curated refs file (.github/dsbaseclient-refs.txt)
################################################################################
name: dsBaseClient tests' suite

on:
  push:
  schedule:
    - cron: '0 0 * * 6'   # weekly
    # - cron: '0 1 * * *'   # nightly
  workflow_dispatch:

env:
  TARGET_REPOSITORY: datashield/dsBaseClient
  PROJECT_NAME: dsBaseClient

jobs:
  set-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.build.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4

      - name: Build matrix from file (.github/dsbaseclient-refs.txt)
        id: build
        run: |
          if [ ! -f .github/dsbaseclient-refs.txt ]; then
            echo "ERROR: .github/dsbaseclient-refs.txt not found."
            exit 1
          fi

          FILE=".github/dsbaseclient-refs.txt"

          MATRIX_JSON=$(grep -v '^\s*#' "$FILE" | grep -v '^\s*$' | awk -F= '
            {
              label=$1
              ref=$2
              dsdangerclient=$3
              gsub(/^[ \t]+|[ \t]+$/, "", label)
              gsub(/^[ \t]+|[ \t]+$/, "", ref)
              gsub(/^[ \t]+|[ \t]+$/, "", dsdangerclient)
              printf "{\"label\":\"%s\",\"ref\":\"%s\",\"dsdangerclient\":\"%s\"}\n", label, ref, dsdangerclient
            }
          ' | jq -s -c '.')

          echo "matrix=$MATRIX_JSON" >> $GITHUB_OUTPUT

  dsBaseClient_test_suite:
    needs: set-matrix
    runs-on: ubuntu-latest
    timeout-minutes: 180
    permissions:
      contents: write

    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJson(needs.set-matrix.outputs.matrix) }}

    env:
      TEST_FILTER: '_-|datachk-|smk-|arg-|disc-|perf-|smk_expt-|expt-|math-'
      REF_NAME: ${{ matrix.ref }}
      REF_LABEL: ${{ matrix.label }}
      REF_DSDANGERCLIENT: ${{ matrix.dsdangerclient }}
      WORKFLOW_ID: ${{ github.run_id }}-${{ github.run_attempt }}-${{ matrix.ref }}

    steps:
      - name: Checkout dsBaseClient
        uses: actions/checkout@v4
        with:
          repository: ${{ env.TARGET_REPOSITORY }}
          token: ${{ github.token }}
          ref: ${{ matrix.ref }}
          fetch-depth: 0
          path: dsBaseClient

      - name: Checkout dsTestsDashboard
        uses: actions/checkout@v4
        with:
          path: dsTestsDashboard

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libxml2-dev \
            libcurl4-openssl-dev \
            libssl-dev \
            libgsl-dev \
            libgit2-dev \
            libharfbuzz-dev \
            libfribidi-dev \
            libmagick++-dev \
            xml-twig-tools

      - uses: r-lib/actions/setup-pandoc@v2

      - uses: r-lib/actions/setup-r@v2
        with:
          r-version: release
          http-user-agent: release
          use-public-rspm: true

      - uses: r-lib/actions/setup-r-dependencies@v2
        with:
          working-directory: dsBaseClient
          dependencies: 'c("Imports", "Suggests")'
          cache-version: 1
          needs: check
          extra-packages: |
            cran::MolgenisArmadillo

      - name: Install dsDangerClient and dependencies
        run: |
          echo "Installing dsDangerClient/$REF_DSDANGERCLIENT and dependencies"
          sudo apt-get update
          sudo apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev  # Required system dependencies for R packages
          R -e "install.packages('devtools')"  # Install devtools if it's not already installed
          R -e "devtools::install_github('datashield/dsDangerClient', ref = '${{ matrix.dsdangerclient }}')"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Devtools checks
        run: |
          R -q -e "devtools::check(args = c('--no-examples', '--no-tests'))"
        working-directory: dsBaseClient
        continue-on-error: true

      - name: Start Armadillo
        run: docker compose -f docker-compose_armadillo.yml up -d
        working-directory: dsBaseClient

      - name: Wait for Armadillo API
        run: |
          echo "Waiting for Armadillo..."
          until curl -s http://localhost:8080/packages > /dev/null; do
            sleep 5
          done
          echo "Armadillo ready."

      - name: Install test datasets
        run: |
          R -q -f "molgenis_armadillo-upload_testing_datasets.R"
        working-directory: dsBaseClient/tests/testthat/data_files

      - name: Install latest dsBase to Armadillo
        run: |
          set -e

          echo "Looking for dsBase_* -permissive tarballs..."
          ls -1 dsBase_*-permissive.tar.gz || true

          # find latest version using version sort (-V handles X.Y.Z correctly)
          LATEST_TARBALL=$(ls -1 dsBase_*-permissive.tar.gz 2>/dev/null | sort -V | tail -n 1)

          if [ -z "$LATEST_TARBALL" ]; then
            echo "❌ No dsBase_* -permissive.tar.gz file found in repo"
            exit 1
          fi

          echo "✅ Latest dsBase package detected: $LATEST_TARBALL"

          # extract version for logging
          VERSION=$(echo "$LATEST_TARBALL" | sed -E 's/^dsBase_([0-9.]+)-permissive\.tar\.gz$/\1/')
          echo "Installing dsBase version: $VERSION"

          # check Armadillo API is reachable
          curl -u admin:admin -X GET http://localhost:8080/packages

          # install the latest tarball
          curl -u admin:admin \
            -H 'Content-Type: multipart/form-data' \
            -F "file=@${LATEST_TARBALL}" \
            -X POST http://localhost:8080/install-package

          docker restart dsbaseclient-armadillo-1

          until curl -s http://localhost:8080/packages > /dev/null; do
            sleep 5
          done

          # whitelist dsBase (package name stays constant)
          curl -u admin:admin -X POST http://localhost:8080/whitelist/dsBase
        working-directory: dsBaseClient

      - name: Run tests with coverage & JUnit report
        run: |
          mkdir -p logs
          R -q -e "devtools::reload();"
          R -q -e '
            options(warn = 1);
            options("datashield.return_errors" = FALSE, "default_driver" = "ArmadilloDriver");

            cat("=== Running testthat directly (debug mode) ===\n");
            cat("Working directory:", getwd(), "\n");
            cat("R version:", R.version.string, "\n");

            junit_rep <- testthat::JunitReporter$new(
              file = file.path(getwd(), "test_results.xml")
            );

            progress_rep <- testthat::ProgressReporter$new(
              max_failures = Inf
            );

            multi_rep <- testthat::MultiReporter$new(
              reporters = list(progress_rep, junit_rep)
            );

            # Check if the tests are in the right place
            cat("Tests found in:", list.files(path = "dsBaseClient/tests/testthat", full.names = TRUE), "\n");

            # Alternatively check a different path:
            cat("ALTERNATIVE PATH\n");
            cat("Tests found in:", list.files(path = "tests/testthat", full.names = TRUE), "\n");
            # Run tests with full output
            testthat::test_dir("dsBaseClient/tests/testthat",
              filter = "${{ env.TEST_FILTER }}",
              reporter = multi_rep,
              stop_on_failure = FALSE
            )
          '

          mv coveragelist.csv logs/
          mv test_* logs/
          grep -q " FAIL 0 " logs/test_console_output.txt
        working-directory: dsBaseClient

      - name: Check for JUnit errors
        run: |
          issue_count=$(sed 's/failures="0" errors="0"//' test_results.xml | grep -c errors= || true)
          echo "Number of testsuites with issues: $issue_count"
          sed 's/failures="0" errors="0"//' test_results.xml | grep errors= > issues.log || true
          cat issues.log || true
          exit $issue_count
        working-directory: dsBaseClient/logs

      - name: Write versions to file
        run: |
          echo "ref:${{ env.REF_NAME }}" > ${{ env.WORKFLOW_ID }}.txt
          echo "ref_label:${{ env.REF_LABEL }}" >> ${{ env.WORKFLOW_ID }}.txt
          echo "os:$(lsb_release -ds)" >> ${{ env.WORKFLOW_ID }}.txt
          echo "R:$(R --version | head -n1)" >> ${{ env.WORKFLOW_ID }}.txt
          Rscript --vanilla -e 'sessionInfo()' >> session_info_${{ env.WORKFLOW_ID }}.txt
        working-directory: dsBaseClient/logs

      - name: Upload logs artefact
        uses: actions/upload-artifact@v4
        with:
          name: logs-ref_${{ matrix.ref }}-label_${{ matrix.label }}
          path: dsBaseClient/logs
          if-no-files-found: error

      - name: Dump environment (on failure)
        if: failure()
        run: |
          echo -e "\n#############################"
          echo -e "ls /: ######################"
          ls -al .
          echo -e "\n#############################"
          echo -e "lscpu: ######################"
          lscpu
          echo -e "\n#############################"
          echo -e "memory: #####################"
          free -m
          echo -e "\n#############################"
          echo -e "env: ########################"
          env
          echo -e "\n#############################"
          echo -e "R sessionInfo(): ############"
          R -e 'sessionInfo()'
          sudo apt install tree -y
          tree .

  publish-results:
    name: Publish aggregated results
    needs: dsBaseClient_test_suite
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout dsTestsDashboard
        uses: actions/checkout@v4
        with:
          path: dsTestsDashboard
          fetch-depth: 0

      - name: Download all artefacts
        uses: actions/download-artifact@v4
        with:
          path: artefacts

      - name: Merge artefacts into dashboard structure
        run: |
          set -e
          cd dsTestsDashboard

          echo "Artefacts downloaded:"
          ls -R ../artefacts || true

          for dir in ../artefacts/logs-*; do
            if [ -d "$dir" ]; then
              BASENAME=$(basename "$dir")

              # extract ref (between logs-ref_ and -label_)
              REF="${BASENAME#logs-ref_}"
              REF="${REF%%-label_*}"

              # extract label (after -label_)
              LABEL="${BASENAME#*-label_}"

              echo "Processing:"
              echo "  ref:   $REF"
              echo "  label: $LABEL"

              WORKFLOW_ID="${{ github.run_id }}-${{ github.run_attempt }}-${REF}"
              TARGET_DIR="logs/${{ env.PROJECT_NAME }}/${LABEL}/${WORKFLOW_ID}/"
              mkdir -p "$TARGET_DIR"
              cp -rv "$dir"/* "$TARGET_DIR" || true
            fi
          done
        env:
          PROJECT_NAME: ${{ env.PROJECT_NAME }}
